root@129-213-82-165:/brandon/evilevo/evo2# infer_evo2 --ckpt-dir pretraining_demo/evo2/checkpoints/epoch\=0-step\=349-consu
med_samples\=22400.0/ --prompt AAAAAAA
Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/nemo/utils/import_utils.py", line 319, in safe_import_from
    return getattr(imported_module, symbol), True
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'

INFO:nemo.utils.import_utils:Import of quick_gelu from megatron.core.fusions.fused_bias_geglu failed with: Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/nemo/utils/import_utils.py", line 319, in safe_import_from
    return getattr(imported_module, symbol), True
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'megatron.core.fusions.fused_bias_geglu' has no attribute 'quick_gelu'

INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] Rank 0 has data parallel group : [0]
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] Ranks 0 has data parallel rank: 0
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] Rank 0 has context parallel group: [0]
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] All context parallel group ranks: [[0]]
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] Ranks 0 has context parallel rank: 0
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] Rank 0 has model parallel group: [0]
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] All model parallel group ranks: [[0]]
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] Rank 0 has tensor model parallel group: [0]
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] All tensor model parallel group ranks: [[0]]
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] Rank 0 has tensor model parallel rank: 0
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] Rank 0 has embedding group: [0]
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] All pipeline model parallel group ranks: [[0]]
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] Rank 0 has pipeline model parallel rank 0
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] All embedding group ranks: [[0]]
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] Rank 0 has embedding rank: 0
INFO:pytorch_lightning.utilities.rank_zero:----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[NeMo I 2025-11-23 01:07:39 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.
[NeMo I 2025-11-23 01:07:40 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 1108204800
[NeMo I 2025-11-23 01:07:40 nemo_logging:393] Doing selective restore from RestoreConfig(path='pretraining_demo/evo2/checkpoints/epoch=0-step=349-consumed_samples=22400.0/', load_model_state=True, load_optim_state=False, load_artifacts=True)
WARNING:megatron.core.dist_checkpointing.serialization:DEPRECATED: Passing 'checkpoint_dir' as a Path object in load_common_state_dict will no longer be supported in a future release. Please pass it as a string instead.
[NeMo I 2025-11-23 01:07:40 nemo_logging:393] Loaded sharded_state_dict_metadata from checkpoint: {'distrib_optim_sharding_type': 'fully_sharded_model_space'}
[NeMo I 2025-11-23 01:07:40 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x73b5859ba750> dist-ckpt load strategy.
WARNING:megatron.core.dist_checkpointing.validation:Some keys found in the checkpoint are missing in the provided sharded state dict. 
Missing keys (for all ranks): {'optimizer.state.fp32_param.module.decoder.layers.6.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.5.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.1.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.mixer.filter.p', 'optimizer.state.fp32_param.module.decoder.layers.8.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.9.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.21.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.final_norm.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.17.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.5.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.19.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.11.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.4.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.17.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.5.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.6.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.21.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg.module.decoder.layers.14.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.22.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.mixer.filter.gamma', 'optimizer.state.fp32_param.module.decoder.layers.5.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.5.mixer.mixer.filter.h', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.19.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.22.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.mixer.filter.R', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.mixer.filter.p', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.mixer.filter.R', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.19.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.15.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.8.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.13.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.10.self_attention.linear_proj.bias', 'optimizer.state.fp32_param.module.decoder.layers.1.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.22.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.24.self_attention.linear_proj.weight', 'optimizer.state.fp32_param.module.decoder.layers.14.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.22.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.12.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg.module.decoder.layers.15.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.mixer.filter.p', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.20.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.7.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.21.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.7.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.24.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.12.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.mixer.filter.gamma', 'optimizer.state.fp32_param.module.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.12.mixer.mixer.filter.h', 'optimizer.state.fp32_param.module.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.mixer.filter.p', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.mixer.filter.p', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.19.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.15.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.15.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.22.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.18.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.24.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.21.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.21.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.mixer.filter.R', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.24.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.15.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.12.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.15.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.2.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.13.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg.module.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.17.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.3.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.0.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.10.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.3.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg.module.decoder.layers.19.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.15.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.18.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.24.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.8.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.24.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.17.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.mixer.filter.R', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.8.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.21.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.19.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.24.self_attention.linear_proj.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.22.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.7.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.6.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.mixer.filter.gamma', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mixer.mixer.filter.h', 'optimizer.state.fp32_param.module.decoder.layers.0.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.mixer.filter.gamma', 'optimizer.state.fp32_param.module.decoder.layers.22.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.18.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.0.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.14.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.final_norm.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.mixer.filter.R', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.3.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.15.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.5.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.22.mixer.mixer.filter.h', 'optimizer.state.fp32_param.module.decoder.layers.17.self_attention.linear_proj.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.10.self_attention.linear_proj.weight', 'optimizer.state.fp32_param.module.decoder.layers.8.mixer.mixer.filter.h', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.11.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.0.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.15.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.24.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.15.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.19.mixer.mixer.filter.h', 'optimizer.state.exp_avg.module.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.14.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.5.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.7.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.3.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.12.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.11.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.5.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.12.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.3.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.8.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.22.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.17.self_attention.linear_proj.bias', 'optimizer.state.exp_avg.module.decoder.layers.13.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.21.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.17.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.mixer.filter.p', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.22.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.5.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.0.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mixer.mixer.filter.h', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.14.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.17.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.mixer.filter.p', 'optimizer.state.exp_avg.module.decoder.layers.9.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.mixer.filter.p', 'optimizer.state.exp_avg.module.decoder.layers.19.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.0.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg.module.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.11.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.8.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.mixer.filter.p', 'optimizer.state.fp32_param.module.decoder.layers.17.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.2.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.mixer.filter.gamma', 'optimizer.state.fp32_param.module.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.7.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.10.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg.module.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.11.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.4.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.final_norm.weight', 'optimizer.state.fp32_param.module.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.4.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.4.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.20.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.7.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.embedding.word_embeddings.weight', 'optimizer.state.exp_avg.module.decoder.layers.18.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.mixer.filter.p', 'optimizer.state.fp32_param.module.decoder.layers.24.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.embedding.word_embeddings.weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.4.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.mixer.filter.p', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.mixer.filter.R', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.15.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.0.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mixer.mixer.filter.h', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.20.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.11.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.21.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.8.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg_sq.module.decoder.layers.10.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.10.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.7.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.22.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.11.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.21.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.8.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.15.mixer.mixer.filter.h', 'optimizer.state.exp_avg_sq.module.decoder.layers.17.self_attention.linear_proj.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mixer.mixer.filter.h', 'optimizer.state.exp_avg.module.decoder.layers.15.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.5.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.5.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.3.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.14.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.18.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.10.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg.module.decoder.layers.18.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.24.self_attention.linear_proj.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.10.self_attention.linear_proj.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.12.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.11.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.0.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.11.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.14.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.24.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.12.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.16.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.mixer.filter.p', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.8.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.5.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.8.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.15.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.21.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.4.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.20.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.24.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.14.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.1.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.14.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.4.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.mixer.filter.R', 'optimizer.state.exp_avg.module.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.1.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.14.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.22.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.7.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.17.self_attention.linear_proj.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg.module.decoder.layers.10.self_attention.linear_proj.bias', 'optimizer.state.fp32_param.module.decoder.layers.5.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.24.self_attention.linear_proj.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.8.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.17.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.1.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.11.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.10.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.17.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.13.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.15.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.17.self_attention.linear_proj.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.10.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.4.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.3.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.4.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.1.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.5.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.17.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg.module.decoder.layers.14.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.8.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.4.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.19.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.3.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.3.self_attention.linear_proj.bias', 'optimizer.state.fp32_param.module.decoder.layers.1.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.10.self_attention.linear_proj.bias', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.mixer.filter.p', 'optimizer.state.fp32_param.module.decoder.layers.6.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.18.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.14.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.18.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.11.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mixer.mixer.filter.h', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.14.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.12.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.23.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.mixer.filter.p', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.17.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.10.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.5.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.3.self_attention.linear_proj.bias', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.mixer.filter.R', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.15.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.7.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.7.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.16.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.8.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.0.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.12.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.24.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.0.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.21.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.0.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.3.self_attention.linear_proj.weight', 'optimizer.state.exp_avg.module.decoder.layers.4.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.21.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mixer.mixer.filter.h', 'optimizer.state.exp_avg.module.decoder.layers.12.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.5.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.mixer.filter.p', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.11.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.8.mixer.mixer.filter.h', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.10.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.18.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.0.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.22.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.mixer.filter.p', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.12.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.5.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.10.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.21.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.11.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.1.mixer.mixer.filter.h', 'optimizer.state.exp_avg_sq.module.decoder.layers.21.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.20.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.4.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.24.self_attention.linear_proj.bias', 'optimizer.state.exp_avg.module.decoder.layers.13.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.7.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.21.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.9.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.14.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.24.self_attention.linear_qkv.weight', 'optimizer.state.fp32_param.module.decoder.layers.1.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.13.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mixer.mixer.filter.h', 'optimizer.state.exp_avg.module.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.8.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.20.mixer.mixer.filter.p', 'optimizer.state.exp_avg.module.decoder.layers.8.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.mixer.filter.R', 'optimizer.state.exp_avg.module.decoder.layers.7.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.5.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.3.self_attention.linear_proj.weight', 'optimizer.state.exp_avg.module.decoder.layers.22.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.3.self_attention.linear_proj.bias', 'optimizer.state.exp_avg.module.decoder.layers.17.self_attention.linear_proj.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.mixer.filter.R', 'optimizer.state.fp32_param.module.decoder.layers.7.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.7.mixer.dense.bias', 'optimizer.state.exp_avg.module.embedding.word_embeddings.weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mixer.mixer.filter.h', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.8.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.22.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.0.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mixer.mixer.filter.h', 'optimizer.state.fp32_param.module.decoder.layers.6.mixer.mixer.filter.R', 'optimizer.state.exp_avg.module.decoder.layers.2.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.10.self_attention.linear_proj.weight', 'optimizer.state.fp32_param.module.decoder.layers.0.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.20.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.2.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.3.self_attention.linear_qkv.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.3.self_attention.linear_proj.weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.22.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.18.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.18.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.16.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg.module.decoder.layers.5.mixer.mixer.filter.h', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.12.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.19.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mixer.dense_projection.weight', 'optimizer.state.exp_avg.module.decoder.layers.16.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.mixer.filter.R', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.12.mixer.mixer.conv_bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.mixer.filter.p', 'optimizer.state.exp_avg.module.decoder.layers.12.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.3.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.7.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.10.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mixer.dense.weight', 'optimizer.state.fp32_param.module.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.dense_projection.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.1.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.mixer.filter.gamma', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.24.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.12.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.18.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.4.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.11.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mixer.dense.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg.module.decoder.layers.18.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.24.self_attention.linear_proj.bias', 'optimizer.state.exp_avg_sq.module.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.fp32_param.module.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.14.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.6.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.4.mlp.linear_fc2.weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mixer.mixer.conv_bias', 'optimizer.state.fp32_param.module.decoder.layers.12.mixer.mixer.filter.h', 'optimizer.state.exp_avg_sq.module.decoder.layers.17.self_attention.linear_qkv.weight', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.13.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.15.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.3.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.2.mixer.mixer.filter.gamma', 'optimizer.state.fp32_param.module.decoder.layers.0.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.6.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.mixer.filter.p', 'optimizer.state.exp_avg.module.decoder.layers.9.mixer.mixer.filter.p', 'optimizer.state.exp_avg.module.decoder.layers.6.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.22.mixer.mixer.conv_bias', 'optimizer.state.exp_avg.module.decoder.layers.12.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.15.mixer.dense.weight', 'optimizer.state.exp_avg.module.decoder.layers.15.mixer.mixer.filter.h', 'optimizer.state.exp_avg_sq.module.decoder.layers.18.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.16.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.4.mixer.dense.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.9.mixer.mixer.filter.p', 'optimizer.state.fp32_param.module.decoder.layers.13.mlp.linear_fc2.weight', 'optimizer.state.exp_avg.module.decoder.layers.18.mlp.linear_fc1.weight', 'optimizer.state.exp_avg.module.decoder.layers.11.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.2.mixer.dense_projection.weight', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.8.mlp.linear_fc2.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.dense.bias', 'optimizer.state.exp_avg.module.decoder.layers.10.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.12.mlp.linear_fc1.layer_norm_weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.3.mlp.linear_fc1.weight', 'optimizer.state.exp_avg_sq.module.decoder.layers.23.mixer.dense_projection.layer_norm_weight', 'optimizer.state.fp32_param.module.decoder.layers.9.mlp.linear_fc1.weight', 'optimizer.state.fp32_param.module.decoder.layers.20.mixer.mixer.filter.gamma', 'optimizer.state.fp32_param.module.decoder.layers.9.mixer.dense_projection.layer_norm_weight', 'optimizer.state.exp_avg.module.decoder.layers.22.mixer.dense.bias', 'optimizer.state.fp32_param.module.decoder.layers.22.mixer.mixer.filter.h', 'optimizer.state.fp32_param.module.decoder.layers.23.mixer.dense.weight'}. 
[NeMo I 2025-11-23 01:08:02 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1763860060.255s : Time spent in load_checkpoint: 21.928s
[NeMo I 2025-11-23 01:08:02 nemo_logging:393] Restoring model weights from RestoreConfig(path='pretraining_demo/evo2/checkpoints/epoch=0-step=349-consumed_samples=22400.0/', load_model_state=True, load_optim_state=False, load_artifacts=True)
[NeMo I 2025-11-23 01:08:02 nemo_logging:393] Finished restoring from RestoreConfig(path='pretraining_demo/evo2/checkpoints/epoch=0-step=349-consumed_samples=22400.0/', load_model_state=True, load_optim_state=False, load_artifacts=True), cleaning up.
static requests: 100%|| 1/1 [00:25<00:00, 25.44s/it]
Inference time: 25.44135706 seconds, 40.2887313590496 tokens/sec
[NeMo I 2025-11-23 01:08:27 nemo_logging:393] [InferenceRequest(request_id='0', prompt='AAAAAAA', sampling_params=SamplingParams(temperature=1.0, top_k=0, top_p=0.0, return_log_probs=False, return_segments=False, num_tokens_to_generate=1024, top_n_logprobs=0, return_prompt_top_n_logprobs=False), inference_parameters=None, prompt_tokens=[65, 65, 65, 65, 65, 65, 65], arrival_time=1763860082.190673, status=<Status.COMPLETED: 4>, encoder_prompt=None, generated_text='ATCAACCCGCCCCGGGTGTGCGATGTACGTATTTAGCGAATAGTAAATATCCTGTTGCTCCAAACAGTTTAGCTGGACAAAGGTCACCAAACGCATGATGTGCCAATTGCTTACTGGAGTATAAATAAACCAAATTGTTCCGTGAAGGTGCCAAGCCTCTAGGAGCCAGGTTTCATTTTCCCGTAAAAAAATAAGGCCCAAGGGTGCAGGCCGCTCAATACTATAGTCTTAATATTTCTGGGTAGTCGAGTTGCGGAAACACCAATGAAATTAGGTGGAGATGGGTCACTTGTGAGTACACTATTTATACGTGTACAAGACTTAAGGATGGTAAATAGACGTTTAGGATTTAATGCTGTTACATACATATAAGACCCTCTCTAAAATAGACACCTACGATAAGATTGTATCTAAGCATTCAATGCAGAAAGCAGAGGCTGTTGAAAAGGCATATAATCCTAGCATATCTACGGGGGTGGAAAAGATCAAAAATATACGCGAAGGAAAGTTTTCAAGACTAAATAGATTCGAGCTCCTACTACCTATTTGCTGGTACTAAATGTCTCAGGGAGGTATACAGTAGCCAAATTAGGTTCAATTAGATGATTACTGAAGTAACATATCTCAATGTCTTTACGAGACACACATTTTGTAAAATGGAAACACAAGCGGGATTGTTTTGCAAACGACGAACGGAAGGTGGTTATTCGTTACTGACAATAATCGCCAGGAAATTAACTGACGCCGGCGCTAGTGACAAAGAATACAATCTGCAGGATCGGAGGCATTTGAATGACGTTGACTTAACTTACTGAGAATACTTGGAATGCGTTGATGTGCTTTAATAAGCAATGGCCGCTTCCGCGAAATAAATATTCAACAACTAATGTAGTTATATGGACTTCTTGAGAACAAGCAACGCAGGATAAAATTAATTGGAAGCAATTGCTGAGTACGCAAACACCAGATTGAGATGTTGGTATAACGCAAAGGCGAGATGAAGATGGATACTCGCTGGTAGAAT', segments=None, generated_segments=None, generated_sequence_lengths=tensor([1024], device='cuda:0', dtype=torch.int32), generated_tokens=tensor([65, 84, 67,  ..., 65, 65, 84], device='cuda:0'), prompt_log_probs=None, generated_log_probs=None, prompt_top_n_logprobs=None, generated_top_n_logprobs=None, generated_length=1024, tpot=[2.4695208072662354, 0.21065187454223633, 0.022802241146564484, 0.022297216579318047, 0.022530270740389824, 0.0223347507417202, 0.022257503122091293, 0.022357599809765816, 0.022127680480480194, 0.0220487043261528, 0.02225017547607422, 0.02242051064968109, 0.022356001660227776, 0.0221717432141304, 0.022089824080467224, 0.022244127467274666, 0.02215820923447609, 0.022175326943397522, 0.022201985120773315, 0.022067071869969368, 0.022300416603684425, 0.02210828848183155, 0.021994655951857567, 0.02228252775967121, 0.021966977044939995, 0.02209923230111599, 0.0221234243363142, 0.02226211130619049, 0.022314848378300667, 0.02214764803647995, 0.02214745432138443, 0.02200278453528881, 0.025440704077482224, 0.022334367036819458, 0.021998688578605652, 0.02202988788485527, 0.022084543481469154, 0.022045055404305458, 0.02192028798162937, 0.021920926868915558, 0.022053951397538185, 0.022061599418520927, 0.022052640095353127, 0.02209305576980114, 0.022054720669984818, 0.022134238854050636, 0.022185087203979492, 0.022213120013475418, 0.021990079432725906, 0.0219010878354311, 0.02201683260500431, 0.021889280527830124, 0.022046655416488647, 0.022408705204725266, 0.021956607699394226, 0.022187136113643646, 0.022110559046268463, 0.02223689667880535, 0.022201281040906906, 0.022139040753245354, 0.02195558324456215, 0.02223632112145424, 0.02217193692922592, 0.02211167849600315, 0.022168895229697227, 0.022112255915999413, 0.022195104509592056, 0.02217494323849678, 0.022220928221940994, 0.021968897432088852, 0.022078687325119972, 0.022059936076402664, 0.022188320755958557, 0.022179456427693367, 0.022000929340720177, 0.022190464660525322, 0.02195724844932556, 0.022056320682168007, 0.022114016115665436, 0.022519327700138092, 0.022068031132221222, 0.022159518674016, 0.022146912291646004, 0.022075392305850983, 0.022107169032096863, 0.022005600854754448, 0.022378558292984962, 0.02210927940905094, 0.022195104509592056, 0.022146720439195633, 0.02219199948012829, 0.022159583866596222, 0.02215500921010971, 0.022055072709918022, 0.022181088104844093, 0.02281203307211399, 0.02208131179213524, 0.022141024470329285, 0.02305731177330017, 0.02202233485877514, 0.02212393656373024, 0.023549184203147888, 0.02206358313560486, 0.02212185598909855, 0.0221859198063612, 0.022068191319704056, 0.022137343883514404, 0.02203040011227131, 0.022094015032052994, 0.021996447816491127, 0.0221252478659153, 0.022089248523116112, 0.02207132801413536, 0.022263584658503532, 0.021943967789411545, 0.02216070331633091, 0.022177280858159065, 0.022119935601949692, 0.022168319672346115, 0.022040031850337982, 0.022092832252383232, 0.02210691198706627, 0.03992803022265434, 0.022081663832068443, 0.02207990363240242, 0.022151680663228035, 0.022024448961019516, 0.02209184132516384, 0.022073183208703995, 0.022233599796891212, 0.02212652750313282, 0.02200896106660366, 0.02309379167854786, 0.022116225212812424, 0.0221257284283638, 0.02303011156618595, 0.022124959155917168, 0.02204803191125393, 0.022246751934289932, 0.022078176960349083, 0.0220224317163229, 0.022213855758309364, 0.022181473672389984, 0.02526531182229519, 0.02217523194849491, 0.022157792001962662, 0.02208566479384899, 0.02228444814682007, 0.02203756757080555, 0.02202620916068554, 0.022212320938706398, 0.022130047902464867, 0.022194240242242813, 0.022121792659163475, 0.021976415067911148, 0.022154079750180244, 0.022154144942760468, 0.021967198699712753, 0.02225535921752453, 0.022125503048300743, 0.02213907241821289, 0.02219078503549099, 0.022136032581329346, 0.022166240960359573, 0.022174783051013947, 0.02210073731839657, 0.0221016313880682, 0.022077057510614395, 0.02204803191125393, 0.022276511415839195, 0.02204582467675209, 0.021975550800561905, 0.022109055891633034, 0.022203680127859116, 0.022097889333963394, 0.022095071151852608, 0.022131070494651794, 0.02203238569200039, 0.021999230608344078, 0.022136736661195755, 0.02195804752409458, 0.022045567631721497, 0.02358086407184601, 0.022039616480469704, 0.021966304630041122, 0.022055327892303467, 0.02193763107061386, 0.022073503583669662, 0.022049663588404655, 0.022046271711587906, 0.02204963192343712, 0.02215881459414959, 0.02205279842019081, 0.022168191149830818, 0.02204873599112034, 0.02222166396677494, 0.022138111293315887, 0.022237056866288185, 0.02226988784968853, 0.022104032337665558, 0.022078881040215492, 0.02206924743950367, 0.022066112607717514, 0.022218015044927597, 0.022045152261853218, 0.021945856511592865, 0.022159518674016, 0.022228576242923737, 0.023092351853847504, 0.022013695910573006, 0.0220903679728508, 0.022011648863554, 0.022068960592150688, 0.022155584767460823, 0.022269759327173233, 0.022156480699777603, 0.02215123176574707, 0.022149022668600082, 0.022115232422947884, 0.02212134376168251, 0.022054975852370262, 0.022302912548184395, 0.02211199887096882, 0.02211087942123413, 0.022425439208745956, 0.022166911512613297, 0.02224559895694256, 0.022241055965423584, 0.022201504558324814, 0.02209734357893467, 0.022139232605695724, 0.02218220755457878, 0.022108225151896477, 0.022238366305828094, 0.022096799686551094, 0.021965695545077324, 0.022165952250361443, 0.022208798676729202, 0.022076288238167763, 0.022274304181337357, 0.022085759788751602, 0.022091582417488098, 0.022090496495366096, 0.021916832774877548, 0.021983552724123, 0.022117024287581444, 0.022069120779633522, 0.02225353568792343, 0.02233772911131382, 0.022030431777238846, 0.022355137392878532, 0.022130655124783516, 0.022303039208054543, 0.022171614691615105, 0.022137023508548737, 0.022016417235136032, 0.022092480212450027, 0.02206207998096943, 0.022101888433098793, 0.022128639742732048, 0.022234272211790085, 0.022091776132583618, 0.022236865013837814, 0.022179296240210533, 0.022079743444919586, 0.022037504240870476, 0.02211049571633339, 0.022079871967434883, 0.02216159924864769, 0.022194335237145424, 0.02223481610417366, 0.022195423021912575, 0.022149119526147842, 0.022327488288283348, 0.022100351750850677, 0.02209324762225151, 0.02285539172589779, 0.02193017490208149, 0.02207433432340622, 0.023514561355113983, 0.02228303998708725, 0.02223552018404007, 0.022463807836174965, 0.022212481126189232, 0.02216070331633091, 0.02222364768385887, 0.02214166522026062, 0.022128991782665253, 0.022176062688231468, 0.022188160568475723, 0.02208419144153595, 0.02223443239927292, 0.023027904331684113, 0.0223869439214468, 0.02228883095085621, 0.022119391709566116, 0.02232566475868225, 0.022220192477107048, 0.022108159959316254, 0.022228671237826347, 0.022094272077083588, 0.022172000259160995, 0.02204214408993721, 0.022160353139042854, 0.022263934835791588, 0.022074753418564796, 0.022204384207725525, 0.02210371196269989, 0.022172704339027405, 0.022180479019880295, 0.02212275192141533, 0.022821759805083275, 0.022080320864915848, 0.022157184779644012, 0.023028897121548653, 0.022125696763396263, 0.022667167708277702, 0.022258592769503593, 0.022043967619538307, 0.022236032411456108, 0.022208096459507942, 0.022052288055419922, 0.022104576230049133, 0.022239360958337784, 0.022308960556983948, 0.022078143432736397, 0.022114817053079605, 0.022282367572188377, 0.022289728745818138, 0.022138686850667, 0.023004671558737755, 0.022554144263267517, 0.02249900810420513, 0.022238176316022873, 0.02238665521144867, 0.022412799298763275, 0.022283487021923065, 0.022476671263575554, 0.022315071895718575, 0.022252608090639114, 0.022191839292645454, 0.022171519696712494, 0.02214803174138069, 0.022245503962039948, 0.022124959155917168, 0.022214367985725403, 0.02207500860095024, 0.022145312279462814, 0.02209673635661602, 0.022105855867266655, 0.02204672060906887, 0.02209724858403206, 0.02231132797896862, 0.02217196859419346, 0.022121183574199677, 0.02207711897790432, 0.021972576156258583, 0.02217862382531166, 0.022131135687232018, 0.02204086445271969, 0.02204384095966816, 0.022263167425990105, 0.022158049046993256, 0.022205889225006104, 0.02221251092851162, 0.02218582294881344, 0.022186942398548126, 0.02209145575761795, 0.02208956703543663, 0.02201792038977146, 0.022020544856786728, 0.022148992866277695, 0.022106239572167397, 0.02207033522427082, 0.022038273513317108, 0.02209475077688694, 0.022084735333919525, 0.022026943042874336, 0.022314464673399925, 0.022022400051355362, 0.022051744163036346, 0.022063327953219414, 0.022047679871320724, 0.022139839828014374, 0.02215731330215931, 0.022175487130880356, 0.02223014459013939, 0.022187072783708572, 0.022077439352869987, 0.022018561139702797, 0.022011039778590202, 0.021969087421894073, 0.022069023922085762, 0.022233951836824417, 0.022046305239200592, 0.022157663479447365, 0.02201875112950802, 0.02211478352546692, 0.022172383964061737, 0.022006016224622726, 0.022180384024977684, 0.0221566092222929, 0.02196863852441311, 0.022202495485544205, 0.022172927856445312, 0.022110112011432648, 0.022334687411785126, 0.022083809599280357, 0.022072670981287956, 0.022169824689626694, 0.02216089703142643, 0.02211596816778183, 0.02213241532444954, 0.022078976035118103, 0.022162463515996933, 0.02222982421517372, 0.021995486691594124, 0.02214156650006771, 0.02232588827610016, 0.021959006786346436, 0.0220488328486681, 0.022102177143096924, 0.022029951214790344, 0.022149022668600082, 0.022098911926150322, 0.02210032008588314, 0.022064417600631714, 0.021955456584692, 0.022166112437844276, 0.022106559947133064, 0.022217024117708206, 0.022151486948132515, 0.022048799321055412, 0.022211328148841858, 0.02213311940431595, 0.02216329611837864, 0.02208918333053589, 0.022196833044290543, 0.02270124852657318, 0.022452352568507195, 0.022141791880130768, 0.022223232313990593, 0.02217654511332512, 0.022218208760023117, 0.022163743153214455, 0.022190559655427933, 0.022150687873363495, 0.02217017486691475, 0.022175263613462448, 0.022181279957294464, 0.022151071578264236, 0.02219267189502716, 0.02218422293663025, 0.02197468839585781, 0.022010015323758125, 0.022860031574964523, 0.02217286452651024, 0.022143710404634476, 0.022559328004717827, 0.0221510399132967, 0.02222415991127491, 0.023163361474871635, 0.022199776023626328, 0.02218012884259224, 0.022373344749212265, 0.022106720134615898, 0.022131776437163353, 0.02212313562631607, 0.022326143458485603, 0.02217036858201027, 0.022155679762363434, 0.022091615945100784, 0.022061824798583984, 0.02233881503343582, 0.02214217558503151, 0.02210240066051483, 0.022167649120092392, 0.02223910391330719, 0.02219059132039547, 0.02218300849199295, 0.022229600697755814, 0.022160382941365242, 0.022200096398591995, 0.02200079895555973, 0.022016799077391624, 0.02220671996474266, 0.022137247025966644, 0.02216975949704647, 0.022087328135967255, 0.02197839878499508, 0.022411487996578217, 0.022131584584712982, 0.022012190893292427, 0.023255713284015656, 0.021930528804659843, 0.02267017588019371, 0.022119808942079544, 0.02198387123644352, 0.022264575585722923, 0.022097408771514893, 0.0219713281840086, 0.02210230380296707, 0.022202784195542336, 0.02207961678504944, 0.022005440667271614, 0.022012030705809593, 0.022213472053408623, 0.022204991430044174, 0.022076576948165894, 0.022099297493696213, 0.022135678678750992, 0.022073153406381607, 0.022089343518018723, 0.022033566609025, 0.022158049046993256, 0.0220144335180521, 0.022210687398910522, 0.022157728672027588, 0.022250784561038017, 0.022255072370171547, 0.022185152396559715, 0.022207198664546013, 0.022163711488246918, 0.022079840302467346, 0.022209407761693, 0.02222784049808979, 0.022050494328141212, 0.02210329659283161, 0.022099902853369713, 0.0220723208039999, 0.022183455526828766, 0.022147614508867264, 0.02208627201616764, 0.02217414416372776, 0.02217126451432705, 0.02206326462328434, 0.022127263247966766, 0.022150462493300438, 0.022027967497706413, 0.022182593122124672, 0.022216511890292168, 0.02219913713634014, 0.022048000246286392, 0.02213759906589985, 0.02213430404663086, 0.025460734963417053, 0.0235284473747015, 0.022226400673389435, 0.022135520353913307, 0.02229129523038864, 0.022154849022626877, 0.022083360701799393, 0.022329503670334816, 0.022274047136306763, 0.02232547104358673, 0.022160863503813744, 0.0223679356276989, 0.022128192707896233, 0.02223839983344078, 0.022101761773228645, 0.022097663953900337, 0.022132575511932373, 0.022325344383716583, 0.02222595177590847, 0.02209804765880108, 0.022294526919722557, 0.02223151922225952, 0.022229183465242386, 0.022146334871649742, 0.022140031680464745, 0.022138047963380814, 0.022206144407391548, 0.02209683135151863, 0.022050654515624046, 0.022173918783664703, 0.022154944017529488, 0.022160513326525688, 0.022287040948867798, 0.022132575511932373, 0.022221632301807404, 0.022178366780281067, 0.0221515204757452, 0.022140352055430412, 0.022266464307904243, 0.024423649534583092, 0.022771969437599182, 0.02221916802227497, 0.02236432023346424, 0.022329792380332947, 0.02221468649804592, 0.02214755304157734, 0.02213548868894577, 0.022142112255096436, 0.022271201014518738, 0.02226320095360279, 0.0221808310598135, 0.022292736917734146, 0.022133633494377136, 0.0222402885556221, 0.0222066231071949, 0.022123873233795166, 0.022127872332930565, 0.022243743762373924, 0.022176222875714302, 0.02220144122838974, 0.02223164774477482, 0.022187072783708572, 0.022057311609387398, 0.02240636758506298, 0.02222614549100399, 0.022168735042214394, 0.02222675085067749, 0.02218531258404255, 0.022210432216525078, 0.022274047136306763, 0.02223958447575569, 0.022071391344070435, 0.022154465317726135, 0.022168990224599838, 0.022057345137000084, 0.022155774757266045, 0.021973086521029472, 0.024264704436063766, 0.02242192067205906, 0.022334080189466476, 0.022167135030031204, 0.02219676785171032, 0.02215839922428131, 0.022153086960315704, 0.022263359278440475, 0.022203071042895317, 0.022254975512623787, 0.022261984646320343, 0.022536160424351692, 0.022380447015166283, 0.022242048755288124, 0.022688832134008408, 0.02210860885679722, 0.022170592099428177, 0.023220384493470192, 0.02220582403242588, 0.02224995195865631, 0.022296927869319916, 0.022312095388770103, 0.022125152871012688, 0.022244639694690704, 0.0223313607275486, 0.022227264940738678, 0.022143710404634476, 0.022261664271354675, 0.022163262590765953, 0.022161247208714485, 0.022105824202299118, 0.022354207932949066, 0.022364575415849686, 0.0221953596919775, 0.02219516783952713, 0.022365983575582504, 0.022114943712949753, 0.022127360105514526, 0.02206195332109928, 0.022191936150193214, 0.022102337330579758, 0.02223043330013752, 0.02209075167775154, 0.02207929641008377, 0.022194048389792442, 0.022125856950879097, 0.022321823984384537, 0.022492190822958946, 0.02233881503343582, 0.022775104269385338, 0.022068576887249947, 0.02213171124458313, 0.022953854873776436, 0.022022049874067307, 0.02211107313632965, 0.022827422246336937, 0.02211478352546692, 0.022200865671038628, 0.022072894498705864, 0.022242112085223198, 0.02202851139008999, 0.022044384852051735, 0.0220920629799366, 0.022062048316001892, 0.021975744515657425, 0.022140607237815857, 0.022078881040215492, 0.022112127393484116, 0.022022368386387825, 0.022093825042247772, 0.022132031619548798, 0.022134175524115562, 0.022099873051047325, 0.022862721234560013, 0.022217310965061188, 0.022248191758990288, 0.02240707166492939, 0.02214863896369934, 0.022294623777270317, 0.02207411266863346, 0.02219747193157673, 0.022140223532915115, 0.022123295813798904, 0.022177280858159065, 0.022119969129562378, 0.022098112851381302, 0.02238665521144867, 0.02225673757493496, 0.022068705409765244, 0.022187937051057816, 0.022228576242923737, 0.022222239524126053, 0.02209843322634697, 0.02219555340707302, 0.022152062505483627, 0.022196928039193153, 0.022149886935949326, 0.02212323248386383, 0.022151712328195572, 0.022216415032744408, 0.022045375779271126, 0.022249408066272736, 0.022159649059176445, 0.02208976075053215, 0.02211747132241726, 0.022111328318715096, 0.022149311378598213, 0.022245248779654503, 0.02217833511531353, 0.022478656843304634, 0.022289695218205452, 0.022239649668335915, 0.022011294960975647, 0.02221529558300972, 0.022355200722813606, 0.02213459275662899, 0.022150782868266106, 0.022081345319747925, 0.022074272856116295, 0.022188127040863037, 0.022169984877109528, 0.022130880504846573, 0.0222464632242918, 0.022182943299412727, 0.022181855514645576, 0.022292576730251312, 0.022144734859466553, 0.02215670421719551, 0.022060703486204147, 0.022136608138680458, 0.02214387059211731, 0.0221572145819664, 0.022510558366775513, 0.022183839231729507, 0.022152096033096313, 0.022091936320066452, 0.022229375317692757, 0.02220134437084198, 0.022219743579626083, 0.022181663662195206, 0.022172031924128532, 0.022480254992842674, 0.022568129003047943, 0.022225121036171913, 0.022404257208108902, 0.02232956886291504, 0.02224131114780903, 0.022225985303521156, 0.022274751216173172, 0.022226721048355103, 0.02207433432340622, 0.02263552136719227, 0.02223948948085308, 0.022201407700777054, 0.022226624190807343, 0.022377057000994682, 0.022462528198957443, 0.022302143275737762, 0.022833408787846565, 0.022566495463252068, 0.022806111723184586, 0.02255958318710327, 0.022416960448026657, 0.022398656234145164, 0.022231359034776688, 0.022255392745137215, 0.022319840267300606, 0.02230307273566723, 0.02213836833834648, 0.022252511233091354, 0.02263452671468258, 0.02226758375763893, 0.02219555340707302, 0.022162336856126785, 0.022168990224599838, 0.022086143493652344, 0.022077567875385284, 0.022090623155236244, 0.022049663588404655, 0.022599807009100914, 0.022143134847283363, 0.026642143726348877, 0.02232368104159832, 0.02235238440334797, 0.022152287885546684, 0.0222482867538929, 0.022095071151852608, 0.022182783111929893, 0.02253977581858635, 0.022170431911945343, 0.022120319306850433, 0.02230204828083515, 0.022054176777601242, 0.0227835513651371, 0.022160127758979797, 0.022749409079551697, 0.022055167704820633, 0.022122016176581383, 0.023550942540168762, 0.02219369448721409, 0.022106654942035675, 0.02214892767369747, 0.022252831608057022, 0.022160224616527557, 0.022313889116048813, 0.022216064855456352, 0.022157663479447365, 0.022689983248710632, 0.022092705592513084, 0.022106144577264786, 0.02210460789501667, 0.022303136065602303, 0.022240640595555305, 0.022181760519742966, 0.02217334322631359, 0.02223283238708973, 0.02255878411233425, 0.02222703956067562, 0.022175360471010208, 0.022161057218909264, 0.02214892767369747, 0.022297726944088936, 0.022183936089277267, 0.022069407626986504, 0.02203427068889141, 0.02220860868692398, 0.0225363839417696, 0.022197119891643524, 0.022156480699777603, 0.022154465317726135, 0.02313283085823059, 0.022272031754255295, 0.02217075228691101, 0.02310524694621563, 0.022243328392505646, 0.022124959155917168, 0.03089996799826622, 0.029623743146657944, 0.025567039847373962, 0.02219558320939541, 0.022176479920744896, 0.02215411141514778, 0.022085215896368027, 0.02218659222126007, 0.022137952968478203, 0.022356640547513962, 0.022123487666249275, 0.022233568131923676, 0.022209567949175835, 0.022182848304510117, 0.02204105630517006, 0.02204544097185135, 0.02223900705575943, 0.022276030853390694, 0.022226432338356972, 0.022442784160375595, 0.024518366903066635, 0.022577151656150818, 0.021931776776909828, 0.02227676846086979, 0.022152766585350037, 0.022366143763065338, 0.022114623337984085, 0.02219625748693943, 0.022306112572550774, 0.0222493764013052, 0.022086014971137047, 0.022116705775260925, 0.02210639975965023, 0.02213430404663086, 0.02216966450214386, 0.022103041410446167, 0.02219398319721222, 0.02229567989706993, 0.02215731330215931, 0.022304639220237732, 0.022463615983724594, 0.022259199991822243, 0.022100672125816345, 0.022106176242232323, 0.02210870385169983, 0.022312384098768234, 0.02214364893734455, 0.022248607128858566, 0.022126592695713043, 0.022204384207725525, 0.022256959229707718, 0.02216329611837864, 0.02228982374072075, 0.02218800038099289, 0.022188767790794373, 0.022168191149830818, 0.022345760837197304, 0.02211955189704895, 0.02205071970820427, 0.02221152000129223, 0.02215792052447796, 0.02223232015967369, 0.022280095145106316, 0.022204000502824783, 0.02240748703479767, 0.02214614488184452, 0.022099198773503304, 0.022123584523797035, 0.022236736491322517, 0.02228153683245182, 0.022161567583680153, 0.02215113677084446, 0.02214972861111164, 0.02211398258805275, 0.02212412841618061, 0.022204384207725525, 0.022107968106865883, 0.02214067243039608, 0.022073792293667793, 0.022219903767108917, 0.02210870385169983, 0.022167423740029335, 0.022234272211790085, 0.022141344845294952, 0.022063519805669785, 0.022243648767471313, 0.022281887009739876, 0.022063743323087692, 0.022108959034085274, 0.022159937769174576, 0.022241439670324326, 0.022129246965050697, 0.022099776193499565, 0.022014528512954712, 0.024231713265180588, 0.022309856489300728, 0.022199902683496475, 0.022132480517029762, 0.02219097502529621, 0.02233065664768219, 0.02215292677283287, 0.022260095924139023, 0.02216118387877941, 0.022104864940047264, 0.022053023800253868, 0.022178079932928085, 0.02224508859217167, 0.022161856293678284, 0.022182144224643707, 0.022224031388759613, 0.02211606316268444, 0.02211478352546692, 0.022206272929906845, 0.022137822583317757, 0.02227078378200531, 0.02234249748289585, 0.022121215239167213, 0.022088928148150444, 0.02223580703139305, 0.02222038432955742, 0.022237345576286316, 0.022263679653406143, 0.022189505398273468, 0.022182239219546318, 0.02221209555864334, 0.022060511633753777, 0.022092800587415695, 0.02220332808792591, 0.022195199504494667, 0.022189920768141747, 0.022195104509592056, 0.022140320390462875, 0.02217705547809601, 0.022183552384376526, 0.022466816008090973, 0.022273920476436615, 0.02214076742529869, 0.022330977022647858, 0.022132255136966705, 0.02219199948012829, 0.02276463992893696, 0.02218371257185936, 0.022331424057483673, 0.022427871823310852, 0.02217993512749672, 0.02217951975762844, 0.022302014753222466, 0.022134974598884583, 0.022332128137350082, 0.022167520597577095, 0.022179456427693367, 0.022163135930895805, 0.02219955250620842, 0.022149918600916862, 0.02237219177186489, 0.022128287702798843, 0.022123808041214943, 0.022137952968478203, 0.022233599796891212, 0.022182974964380264, 0.02229359932243824, 0.02222057618200779, 0.0222419835627079, 0.02217772789299488, 0.02218889631330967, 0.02213148958981037])]